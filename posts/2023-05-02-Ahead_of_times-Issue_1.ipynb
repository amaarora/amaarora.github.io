{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5d4cb361",
   "metadata": {},
   "source": [
    "---\n",
    "title: Ahead of Times - Issue 1 (Apr 24 - Apr 30)\n",
    "subtitle: First issue of the weekly newsletter to help you stay ahead of the times with latest news & updates in the field of AI. \n",
    "description: | \n",
    "    As part of this newsletter, I share with you key updates, projects, GitHub repos, research trends, research papers in the field of Computer Vision, Large Language Models and Stable Diffusion. \n",
    "categories:\n",
    "  - Newsletter\n",
    "author: Aman Arora\n",
    "date: \"05/02/2023\"\n",
    "toc: true\n",
    "number-sections: true\n",
    "title-block-banner: true\n",
    "bibliography: ../references.bib\n",
    "reference-location: margin\n",
    "code-fold: true\n",
    "image: ../images/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f93d92",
   "metadata": {},
   "source": [
    "![Ahead of Times - Issue 1](../images/newsletter-theme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621a206",
   "metadata": {},
   "source": [
    "# Introduction {#sec-intro}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6671a4",
   "metadata": {},
   "source": [
    "If I am allowed to be a little dramatic, let me present to you the start of a new newsletter called **\"Ahead of Times\"**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4dc4c",
   "metadata": {},
   "source": [
    "As the title suggests, the idea is to stay ahead of the curve. I personally strive my best to keep up to date with the latest research and advancements in the field of AI. As part of this newsletter I wish to take you along on that journey with me. Are you in?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f0c6e",
   "metadata": {},
   "source": [
    "## What does the image signify?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3e848",
   "metadata": {},
   "source": [
    "Since the inception of Neural Nets in 2012 by the godfather of AI - [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton), a lot has changed in terms of our capabilities as a human race to process unstructured data - specifically images and text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0397b",
   "metadata": {},
   "source": [
    "This is even more apparent and visible with the release of chatbots such as [ChatGPT](https://openai.com/blog/chatgpt) with colleagues and employees from different fields (not particularly with a software engineering) utilising the tool in their day to day work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303eb36",
   "metadata": {},
   "source": [
    "In some ways we could say *\"The world of AI is on fire and changing very rapidly\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444dbe1c",
   "metadata": {},
   "source": [
    "**\"Ahead of Times\"** is meant to serve as a newsletter in this \"times of change\" to provide you with the latest news and updates by cutting through the noise & help you steer away from TikTok inspired influencers who write for publicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b0689",
   "metadata": {},
   "source": [
    "## Public commitments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12173822",
   "metadata": {},
   "source": [
    "As the author of **\"Ahead of Times\"**, I publicly commit to: \n",
    "\n",
    "1. Providing a fair assessment of the latest technologies by trying them out myself. \n",
    "2. Being regular in providing you up to date information. \n",
    "3. Provide code examples and snippets where necessary. \n",
    "4. A \"hands on\" practical approach rather than going deep into mathematics/theory. \n",
    "5. Communicate clearly if there are times when I am not able to release the newsletter.\n",
    "6. Open to feedback. \n",
    "7. Promise to not spread misinformation, not be inspired by the \"click bait\" ideology.\n",
    "8. Continue writing the newsletter even if I am the only reader, trust me, it helps when you note things down in writing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96c0fe",
   "metadata": {},
   "source": [
    "With the introductions and some public commitments out of the way, let's get started with some key updates between **\"April 24, 2023 - April 30, 2023\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e453d",
   "metadata": {},
   "source": [
    "# April 24, 2023 - April 30, 2023: Key Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a2fe3",
   "metadata": {},
   "source": [
    "## Stability AI releases DeepFloyd IF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06bb9be",
   "metadata": {},
   "source": [
    ">The theme image for this newsletter was also generated using this model. You can try it our yourself on [here](https://huggingface.co/spaces/DeepFloyd/IF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86789ddf",
   "metadata": {},
   "source": [
    "On April 28, 2012, Stability AI announced the research release of DeepFloyd IF, a powerful text-to-image cascaded pixel diffusion model.\n",
    "\n",
    "Read more about the release on their [official blog here](https://stability.ai/blog/deepfloyd-if-text-to-image-model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87507142",
   "metadata": {},
   "source": [
    "## RedPajama training progress at 440 billion tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68af35",
   "metadata": {},
   "source": [
    "What is RedPajama? Why is this relevant or important? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78821ffb",
   "metadata": {},
   "source": [
    "From the [RedPajama announcement post](https://www.together.xyz/blog/redpajama), \n",
    "\n",
    "*Foundation models such as GPT-4 have driven rapid improvement in AI. However, the most powerful models are closed commercial models or only partially open. RedPajama is a project to create a set of leading, fully open-source models. *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8e75f",
   "metadata": {},
   "source": [
    "Remember \"LLaMA\" (@llama)? Large language models of varying sizes between 7B to 65B released by Meta trained on trillions of tokens on publicly available datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b260a9",
   "metadata": {},
   "source": [
    "Well, as great as it may be, *The original LLaMA code is GPL licensed which means any project using it must also be released under GPL.* What does this mean? *This \"taints\" any other code and prevents meaningful academic and commercial use.* You also have to [apply for access to LLaMA weights](https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform) making them inaccessible. I have personally been waiting a few weeks and never heard back from Meta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb45453",
   "metadata": {},
   "source": [
    "So why is this **RedPajama** project important? Quoting directly from their [blog](https://www.together.xyz/blog/redpajama-training-progress),\n",
    "\n",
    "*Our goal is to train the LLaMA suite of models and make them available under a permissive open-source license so they can be used as a foundation for research and commercial applications.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6da104",
   "metadata": {},
   "source": [
    "Great, right?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ad596",
   "metadata": {},
   "source": [
    "The RedPajama dataset is available on HuggingFace and can be downloaded from [here](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T). All pre-processing and quality filters are open soourced [here](https://github.com/togethercomputer/RedPajama-Data)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c085e",
   "metadata": {},
   "source": [
    "As part of the announcement on April 24, 2023, **Together** announced:\n",
    "\n",
    "*At 440 billion tokens, we now have a model checkpoint that is better than Pythia-7B (0.416 HELM vs. 0.400 HELM) and StableLM-7B (0.283 HELM).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644ac91",
   "metadata": {},
   "source": [
    "Basically, in simpler terms, they conducted a training run with exactly the same model architecture and tokenizer as  Pythia-7B (@pythia), a well-regarded and fully open model from EleutherAI trained on [the Pile](https://pile.eleuther.ai/) (originally released by EleutherAI in 2020). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e181e73e",
   "metadata": {},
   "source": [
    "![A mid training checkpoint of the 7B RedPajama base model, using Pythia architecture, achieves higher quality result on HELM scores than Pythia-7B.](../images/RedPajama-7B-partial-HELM.png){width=60%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4666fe",
   "metadata": {},
   "source": [
    "## Segment Anything in Medical Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6bcee7",
   "metadata": {},
   "source": [
    "Remember Segment Anything Model from Meta?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab941b21",
   "metadata": {},
   "source": [
    "{{< video ../assets/SAM.mov >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeec40e",
   "metadata": {},
   "source": [
    "[Blog](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/) | [Paper](https://ai.facebook.com/research/publications/segment-anything/) | [Code](https://github.com/facebookresearch/segment-anything)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb5abe",
   "metadata": {},
   "source": [
    "Try out the Demo for SAM [here](https://segment-anything.com/demo). In the video that we see above, the model does a great job at segmenting people and vehicles in the image I provided to it. It did miss however some tiny details, but, hey, that's okay for a zero shot model performing segmentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a75ef",
   "metadata": {},
   "source": [
    "From the [Segment Anything in Medical Images](https://arxiv.org/abs/2304.12306), also called **MedSAM** (@medsam), \n",
    "\n",
    "*MedSAM, is the first attempt at extending the success of SAM to medical images, with the goal of creating a universal tool for the segmentation of various medical targets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032eb9e5",
   "metadata": {},
   "source": [
    "You can try out the models in the offical GitHub Repository [here](https://github.com/bowang-lab/MedSAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537700f",
   "metadata": {},
   "source": [
    "> I have personally not tried MedSAM, but if you do, feel free to share your results with me at [@amaarora](https://twitter.com/amaarora)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aca88a",
   "metadata": {},
   "source": [
    "![MedSAM significantly improves the segmentation performance across various\n",
    "modalities and segmentation tasks.](../images/MedSAM.png){width=60%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d1e15",
   "metadata": {},
   "source": [
    "## A Cookbook of Self-Supervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd177a28",
   "metadata": {},
   "source": [
    "From [\"Self-supervised learning: The dark matter of intelligence\"](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/):\n",
    "\n",
    "*Supervised learning is a bottleneck for building more intelligent generalist models that can do multiple tasks and acquire new skills without massive amounts of labeled data. Practically speaking, it’s impossible to label everything in the world.*\n",
    "\n",
    "*Self-supervised learning enables AI systems to learn from orders of magnitude more data, which is important to recognize and understand patterns of more subtle, less common representations of the world.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca4603",
   "metadata": {},
   "source": [
    "Last week, Yann LeCun [shared](https://twitter.com/ylecun/status/1650798206283051009) \"A Cookbook of Self-Supervised Learning\" on Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc7cad",
   "metadata": {},
   "source": [
    "![Contents of \"A Cookbook of Self-Supervised Learning\".](../images/SSL-cookbook.png){width=60%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d523d",
   "metadata": {},
   "source": [
    "**Why a Cookbook for Self-Supervised Learning?** \n",
    "\n",
    "*While many components of SSL are familiar to researchers, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyperparameters. SSL research has a high barrier to entry due to (i) its computational cost, (ii) the absence of fully transparent papers detailing the intricate implementations required to fully enable SSL’s potential, and (iii) the absence of a unified vocabulary and theoretical view of SSL.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1152d",
   "metadata": {},
   "source": [
    "> The above cookbook provides a comprehensive analysis of SSL, hyperparameter tuning, metric learning methods such as SIMCLR (@simclr), evaluation and also deployment! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1815c5ef",
   "metadata": {},
   "source": [
    "## New ways to manage your data in ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b031f",
   "metadata": {},
   "source": [
    "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12af4de",
   "metadata": {},
   "source": [
    "[Announced on April 25, 2023](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt), OpenAI has introduced the ability to turn off Chat History in ChatGPT. \n",
    "\n",
    "This is particularly useful for sharing code snippets related to private and confidential code sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231efefd",
   "metadata": {},
   "source": [
    "## Parameter-Efficient LLM Finetuning With Low-Rank Adaptation (LoRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f315293",
   "metadata": {},
   "source": [
    "As mentioned in @sec-intro, I will also be sharing helpful tutorials as part of the newsletter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c645b4d",
   "metadata": {},
   "source": [
    "One such amazing tutorial released last week by [Sebastian Raschka](https://sebastianraschka.com/) showcases how to finetuning Large Language Models using a technique called LoRA (@lora). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760971d",
   "metadata": {},
   "source": [
    "![Overview of LoRA](../images/lora-img.png){width=50%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8ccec",
   "metadata": {},
   "source": [
    "> What I particularly liked about this blog post were the illustrative images matching pseudo PyTorch code. This is an opportunity for someone to build on top of this tutorial and showcase LoRA with complete working PyTorch code from scratch. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03c2dc",
   "metadata": {},
   "source": [
    "You can find the tutorial shared by Sebastian Raschka [here](https://lightning.ai/pages/community/tutorial/lora-llm/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134a4be",
   "metadata": {},
   "source": [
    "## Replit’s From-Scratch Trained Code Complete model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce841ebc",
   "metadata": {},
   "source": [
    "Before we begin, what is Replit? And why is this relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b6608",
   "metadata": {},
   "source": [
    "Replit is the newest AI unicorn, and they [announced on April 28, 2023](https://techcrunch.com/2023/04/27/replit-funding-100m-generative-ai/) that they've raised nearly `$100M` and are valued at `$1.16B`! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23fa41a",
   "metadata": {},
   "source": [
    "Also, at [Developer Day](https://www.youtube.com/watch?v=7TCqGslll-4), Replit announced: \n",
    "\n",
    "1. Production-grade Deployments straight from IDE\n",
    "2. A more powerful Workspace\n",
    "3. Secure Workspace Extensions\n",
    "4. **Replit’s From-Scratch Trained Code Complete model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88900a86",
   "metadata": {},
   "source": [
    "> The one I am most interested in, is the open source replacement for [Codex](https://openai.com/blog/openai-codex), which Replit has termed \"CodeGen\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a1d5d",
   "metadata": {},
   "source": [
    "Some folks have shared their reviews on CodeGen: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "df5e9de4",
   "metadata": {},
   "source": [
    "<blockquote class=\"twitter-tweet tw-align-center\"><p lang=\"en\" dir=\"ltr\">Despite the recent hype around Replit&#39;s new model, it isn&#39;t actually the best open-source code model out there<br><br>In fact, it&#39;s not even the best 3-billion parameter code model<br><br>That title belongs to Microsoft&#39;s MIM-2.7B... <br><br>And it was trained on 2x fewer tokens! <a href=\"https://t.co/PiE8NpG5Lc\">pic.twitter.com/PiE8NpG5Lc</a></p>&mdash; Aman Sanger (@amanrsanger) <a href=\"https://twitter.com/amanrsanger/status/1651241868993130498?ref_src=twsrc%5Etfw\">April 26, 2023</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3bc45",
   "metadata": {},
   "source": [
    "For further reading:\n",
    "\n",
    "*There is also this really cool [interview with Replit co-founder Amjad Masad by Dan Shipper](https://every.to/chain-of-thought/ai-and-the-future-of-programming).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27812e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593447e4",
   "metadata": {},
   "source": [
    "This brings us to the end of our very first issue of the Newsletter! \n",
    "\n",
    "If you found it helpful, consider subscribing to the blog. You can also buy me a coffee [here](https://www.buymeacoffee.com/amaarora).\n",
    "\n",
    "Thank you for your time! See you next week on Monday at 9am AEST!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
